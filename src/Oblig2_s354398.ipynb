{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./../data/train_data.csv\")\n",
    "test_df = pd.read_csv(\"./../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X\n",
    "1. PassengerId: Unique id for each passenger\n",
    "2. Survived: 0 = No, 1 = Yes\n",
    "3. Pclass: Ticket class\n",
    "4. Sex: sex of the passenger\n",
    "5. SibSp: # of siblings / spouses aboard the Titanic\n",
    "6. Parch: # of parents / children aboard the Titanic\n",
    "7. Ticket: Ticket number\n",
    "8. Fare: Passenger fare\n",
    "9. Cabin: Cabin number (-1 means no data on cabin)\n",
    "10. Embarked: Port of Embarkation\n",
    "\n",
    "Y\n",
    "1. Age: Age in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>346</td>\n",
       "      <td>20.525</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>7.775</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  SibSp  Parch Ticket     Fare  Cabin  \\\n",
       "0          329         1       3    0      1      1    346   20.525     -1   \n",
       "1           74         0       3    1      1      0    166  14.4542     -1   \n",
       "2          254         0       3    1      1      0    419     16.1     -1   \n",
       "3          720         0       3    1      0      0    260    7.775     -1   \n",
       "4          667         0       2    1      0      0    104     13.0     -1   \n",
       "\n",
       "   Embarked   Age  \n",
       "0         2  31.0  \n",
       "1         0  26.0  \n",
       "2         2  30.0  \n",
       "3         2  33.0  \n",
       "4         2  25.0  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get familiar with data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from results .info() there are \"Fare\" and \"Ticket\" have Dtype object. But using .head() we see a numeric values. Probably there is NaN and we need to drop or transform them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's transform our non-alfanumeric values to NaN\n",
    "train_df['Ticket'] = pd.to_numeric(train_df['Ticket'], errors='coerce')\n",
    "train_df['Ticket'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that \"Ticket\" contains 2 NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's transform our non-alfanumeric values to NaN in column \"Fare\"\n",
    "train_df['Fare'] = pd.to_numeric(train_df['Fare'], errors='coerce')\n",
    "train_df['Fare'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Fare\" has 4 NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to have some value there istead of NaN. Let's fill them with mean value\n",
    "train_df[['Ticket', 'Fare']] = train_df[['Ticket', 'Fare']].fillna(train_df[['Ticket', 'Fare']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1493 entries, 0 to 1492\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1493 non-null   int64  \n",
      " 1   Survived     1493 non-null   int64  \n",
      " 2   Pclass       1493 non-null   int64  \n",
      " 3   Sex          1493 non-null   int64  \n",
      " 4   SibSp        1493 non-null   int64  \n",
      " 5   Parch        1493 non-null   int64  \n",
      " 6   Ticket       1493 non-null   float64\n",
      " 7   Fare         1493 non-null   float64\n",
      " 8   Cabin        1493 non-null   int64  \n",
      " 9   Embarked     1493 non-null   int64  \n",
      " 10  Age          1488 non-null   float64\n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 128.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Lets check dtypes again\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that no more objects in our dataset. But Ticket represented as int, but we have it as float now. Let's make it int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1493 entries, 0 to 1492\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1493 non-null   int64  \n",
      " 1   Survived     1493 non-null   int64  \n",
      " 2   Pclass       1493 non-null   int64  \n",
      " 3   Sex          1493 non-null   int64  \n",
      " 4   SibSp        1493 non-null   int64  \n",
      " 5   Parch        1493 non-null   int64  \n",
      " 6   Ticket       1493 non-null   int64  \n",
      " 7   Fare         1493 non-null   float64\n",
      " 8   Cabin        1493 non-null   int64  \n",
      " 9   Embarked     1493 non-null   int64  \n",
      " 10  Age          1488 non-null   float64\n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 128.4 KB\n"
     ]
    }
   ],
   "source": [
    "train_df['Ticket'] = train_df['Ticket'].astype('int64')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>1.488000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>597.697254</td>\n",
       "      <td>0.327528</td>\n",
       "      <td>2.261219</td>\n",
       "      <td>0.690556</td>\n",
       "      <td>0.184863</td>\n",
       "      <td>0.178835</td>\n",
       "      <td>249.171467</td>\n",
       "      <td>19.367148</td>\n",
       "      <td>5.994642</td>\n",
       "      <td>1.834561</td>\n",
       "      <td>2.151174e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>251.365652</td>\n",
       "      <td>0.469469</td>\n",
       "      <td>0.628908</td>\n",
       "      <td>0.462419</td>\n",
       "      <td>0.594308</td>\n",
       "      <td>0.592203</td>\n",
       "      <td>145.543518</td>\n",
       "      <td>33.055481</td>\n",
       "      <td>24.214966</td>\n",
       "      <td>0.538178</td>\n",
       "      <td>8.295612e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.200000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-3.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>758.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>813.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>11.133300</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.200000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId     Survived       Pclass          Sex        SibSp  \\\n",
       "count  1493.000000  1493.000000  1493.000000  1493.000000  1493.000000   \n",
       "mean    597.697254     0.327528     2.261219     0.690556     0.184863   \n",
       "std     251.365652     0.469469     0.628908     0.462419     0.594308   \n",
       "min       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "25%     377.000000     0.000000     2.000000     0.000000     0.000000   \n",
       "50%     758.000000     0.000000     2.000000     1.000000     0.000000   \n",
       "75%     813.000000     1.000000     3.000000     1.000000     0.000000   \n",
       "max     891.000000     1.000000     3.000000     1.000000     5.000000   \n",
       "\n",
       "             Parch       Ticket         Fare        Cabin     Embarked  \\\n",
       "count  1493.000000  1493.000000  1493.000000  1493.000000  1493.000000   \n",
       "mean      0.178835   249.171467    19.367148     5.994642     1.834561   \n",
       "std       0.592203   145.543518    33.055481    24.214966     0.538178   \n",
       "min       0.000000  -496.000000     0.000000    -1.000000    -1.000000   \n",
       "25%       0.000000   181.000000     7.925000    -1.000000     2.000000   \n",
       "50%       0.000000   181.000000    10.500000    -1.000000     2.000000   \n",
       "75%       0.000000   426.000000    11.133300    -1.000000     2.000000   \n",
       "max       6.000000   541.000000   512.329200   133.000000     2.000000   \n",
       "\n",
       "                Age  \n",
       "count  1.488000e+03  \n",
       "mean   2.151174e+05  \n",
       "std    8.295612e+06  \n",
       "min   -3.200000e+04  \n",
       "25%   -3.500000e+01  \n",
       "50%    1.600000e+01  \n",
       "75%    2.400000e+01  \n",
       "max    3.200000e+08  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many outliers in \"Age\" column. We need to handle them. \n",
    "#Setting our ages up to 100 as max\n",
    "train_df = train_df[train_df['Age'] > 0]\n",
    "train_df = train_df[train_df['Age'] <= 100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 541 entries, 0 to 1492\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  541 non-null    int64  \n",
      " 1   Survived     541 non-null    int64  \n",
      " 2   Pclass       541 non-null    int64  \n",
      " 3   Sex          541 non-null    int64  \n",
      " 4   SibSp        541 non-null    int64  \n",
      " 5   Parch        541 non-null    int64  \n",
      " 6   Ticket       541 non-null    int64  \n",
      " 7   Fare         541 non-null    float64\n",
      " 8   Cabin        541 non-null    int64  \n",
      " 9   Embarked     541 non-null    int64  \n",
      " 10  Age          541 non-null    float64\n",
      "dtypes: float64(2), int64(9)\n",
      "memory usage: 50.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop_duplicates()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can commence our model creation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let y be the target column, and X be the rest of the df\n",
    "model1 = xgb.XGBRegressor()\n",
    "X = train_df.drop('Age', axis=1).copy()\n",
    "y = train_df['Age'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per Oblig_2 task - we need to use test_data.csv for evaluation the model, but let's fisrt make evaluation using train_test_split() from sklearn.model.selection. After that we'll make evaluation using test_data.csv and comparison of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets with the function train_test_split from sklearn. Use test_size=0.2 and random_state=42\n",
    "# We use train_test_split to split the data into train and test sets. We will use the train set to train the model, and the test set \n",
    "# to evaluate the model.\n",
    "# The reason we need a test set is to be able to evaluate the model. If we train the model on the whole dataset, \n",
    "# it will learn the dataset perfectly, but we will not know how it performs on unseen data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\envs\\intro-ai\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the training set (X_train, y_train) to train the model by calling the .fit() method\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the target values for the test set (X_test)\n",
    "preds = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.1140071310041"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the mean squared error for the predictions (a value to see the value of the predictions, lower is better)\n",
    "# find the error between the y_test and the preds\n",
    "mse1 = mean_squared_error(preds, y_test)\n",
    "mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.28684734750827"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the root-mean-square\n",
    "rms1 = np.sqrt(mse1)\n",
    "rms1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check our test_df dataset for evaluation and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the target values for the test set (X_test) from test_df (test_data.csv)\n",
    "model2 = xgb.XGBRegressor();\n",
    "X_test_df = test_df.drop('Age', axis=1).copy() # and made a copy\n",
    "Y_test_df = test_df['Age'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\envs\\intro-ai\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.0929148403456"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the mean squared error for the predictions (a value to see the value of the predictions, lower is better)\n",
    "# find the error between the y_test and the preds\n",
    "mse2 = mean_squared_error(preds2, Y_test_df)\n",
    "mse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.291985797272368"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the root-mean-square\n",
    "rms2 = np.sqrt(mse2)\n",
    "rms2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that our model2 which is based on test_data.csv has a better (less) root mean squared error than using train_test_split function from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve our results using XGBoost hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some of the hyperparameters you can tune for XGBoost. \n",
    "# A hyperparameter is a parameter that is not learned by the model, but is set by the user.\n",
    "# The parameters that are learned by the model are called model parameters.\n",
    "# The model starts off with some default values for the hyperparameters, but you can change them to get potentially better results.\n",
    "# This process is called hyperparameter tuning.\n",
    "\n",
    "# If you want, you can adjust the hyperparameters and see if you can get a better result. You can also add more hyperparameters to the \n",
    "# dictionary.\n",
    "# List of hyperparameters: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "params = {\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500, 900, 1100, 1500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\envs\\intro-ai\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1,\n",
       "                                          enable_categorical=False, gamma=0,\n",
       "                                          gpu_id=-1, importance_type=None,\n",
       "                                          interaction_constraints=&#x27;&#x27;,\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints=&#x27;()&#x27;,\n",
       "                                          n_estimato...\n",
       "                                          subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=250, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1,\n",
       "                                          enable_categorical=False, gamma=0,\n",
       "                                          gpu_id=-1, importance_type=None,\n",
       "                                          interaction_constraints=&#x27;&#x27;,\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints=&#x27;()&#x27;,\n",
       "                                          n_estimato...\n",
       "                                          subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=250, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "             validate_parameters=1, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1,\n",
       "                                          enable_categorical=False, gamma=0,\n",
       "                                          gpu_id=-1, importance_type=None,\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimato...\n",
       "                                          subsample=1, tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=250, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomizedSearchCV to find the best hyperparameters for the model. There are other ways to do this, but random search will work for this\n",
    "# purpose.\n",
    "# Random search is a method for hyperparameter tuning that will try a given number of random combinations of hyperparameters.\n",
    "# Use the training set (X_train, y_train) to instantiate the random search by calling the .fit() method with the test set\n",
    "# HINT: n_iter is the number of iterations to run the random search, if this number is too high, it will take a long time to run, \n",
    "# but if it's too low, it will not find the best hyperparameters. You should try to find a happy medium.\n",
    "\n",
    "# First, create a new, similar model, but with the default hyperparameters. Do not fit this model with the training set.\n",
    "random_search1 = RandomizedSearchCV(model1, param_distributions=params, n_iter=250, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=5)\n",
    "random_search2 = RandomizedSearchCV(model2, param_distributions=params, n_iter=250, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=5)\n",
    "# Fit the model with x and y train sets as results using train_test_split function from sklearn.\n",
    "random_search1.fit(X_train, y_train) # Using test_train_split() function from sklearn\n",
    "random_search2.fit(X, y) # Using test_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_model1 = {'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.4}\n",
      "new_model1 = {'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.4, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best model/estimator from the random search\n",
    "model_new1 = random_search1.best_params_\n",
    "model_new2 = random_search2.best_params_\n",
    "# We can compare both parameters sets for our models\n",
    "print(f'new_model1 = {model_new1}')\n",
    "print(f'new_model1 = {model_new2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBRegressor'>\n",
      "<class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    }
   ],
   "source": [
    "model_new1 = random_search1.best_estimator_\n",
    "model_new2 = random_search2.best_estimator_\n",
    "print(type(model_new1))\n",
    "print(type(model_new2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new predictions with the new model\n",
    "preds1 = model_new1.predict(X_test)\n",
    "preds2 = model_new2.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.22276700923595\n",
      "129.995984840456\n"
     ]
    }
   ],
   "source": [
    "# Get the new mean square error\n",
    "new_mse1 = mean_squared_error(preds1, y_test)\n",
    "new_mse2 = mean_squared_error(preds2, Y_test_df)\n",
    "# Comparing both new mse\n",
    "print(new_mse1)\n",
    "print(new_mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After hyperparameters tuning first new model has rms = 11.7\n",
      "After hyperparameters tuning second new model has rms = 11.4\n"
     ]
    }
   ],
   "source": [
    "# Compute the root-mean-square\n",
    "new_rms1 = np.sqrt(new_mse1).round(1)\n",
    "new_rms2 = np.sqrt(new_mse2).round(1)\n",
    "print(f'After hyperparameters tuning first new model has rms = {new_rms1}')\n",
    "print(f'After hyperparameters tuning second new model has rms = {new_rms2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per results: \n",
    "1. After hyperparameters tuning new_model1 has rms = 11.7\n",
    "2. After hyperparameters tuning new_model2 has rms = 11.4\n",
    "3. We can observe that our results are improved and best hyperparameters for models are:\n",
    "4. new_model1 = {'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.4}\n",
    "5. new_model2 ={'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.4, 'colsample_bytree': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation between better error1 on the new model1 and the old error1: 0.8189350467190766\n",
      "Relation between better error2 on the new model2 and the old error2: 0.9274335480057012\n"
     ]
    }
   ],
   "source": [
    "print(f\"Relation between better error1 on the new_model1 and the old error1: {(new_rms1 / rms1)}\")\n",
    "print(f\"Relation between better error2 on the new_model2 and the old error2: {(new_rms2 / rms2)}\")\n",
    "\n",
    "# If the new model did not perform better, this means that the default hyperparameters were better, but it is highly likely that even better ones exist.\n",
    "# You can try to run the random search again, but with more iterations, or you can try to use GridSearchCV instead of RandomizedSearchCV ot test _every_ combination of hyperparameters.\n",
    "# You can also edit the hyperparameters in the dictionary to see if you can get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Relation between better error1 on the new model1 and the old error1: 0.8189350467190766\n",
    "2. Relation between better error2 on the new model2 and the old error2: 0.9274335480057012"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('intro-ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed04c51132b25927b8d3356dcb2f8440b7f7433d6185f1254ba022a830db332c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
